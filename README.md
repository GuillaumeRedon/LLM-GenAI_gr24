# ESILV Smart Assistant

> Assistant conversationnel intelligent pour l'Ã©cole d'ingÃ©nieurs ESILV utilisant la technologie RAG (Retrieval-Augmented Generation) et les modÃ¨les LLM.

## ğŸ“– PrÃ©sentation du projet

**ESILV Smart Assistant** est un chatbot intelligent conÃ§u pour rÃ©pondre aux questions des Ã©tudiants, candidats et visiteurs concernant l'Ã©cole ESILV (programmes, admissions, cours, vie Ã©tudiante, etc.).

Le systÃ¨me combine :
- **RAG (Retrieval-Augmented Generation)** : pour des rÃ©ponses factuelles basÃ©es sur la documentation officielle
- **Architecture multi-agents** : pour gÃ©rer des requÃªtes complexes et des interactions structurÃ©es
- **Interface moderne** : interface web intuitive pour une expÃ©rience utilisateur optimale

### Cas d'usage
- RÃ©pondre aux questions sur les programmes et admissions
- Fournir des informations sur les cours et la vie Ã©tudiante
- Collecter les coordonnÃ©es des visiteurs pour un suivi personnalisÃ©
- Recherche sÃ©mantique dans la documentation ESILV

## ğŸ—ï¸ Architecture

Le projet suit une architecture **client-serveur** moderne :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚ HTTP    â”‚     Backend      â”‚         â”‚    Ollama      â”‚
â”‚   (Next.js)     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   (FastAPI)      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  (LLama3 LLM)  â”‚
â”‚   Port 3000     â”‚         â”‚   Port 8000      â”‚         â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚   ChromaDB     â”‚
                            â”‚ (Vector Store) â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Backend (FastAPI + LangChain)
- API REST pour le chatbot
- SystÃ¨me RAG avec ChromaDB et HuggingFace embeddings
- IntÃ©gration Ollama (Llama3) pour la gÃ©nÃ©ration de rÃ©ponses
- Endpoints : `/v1/ask/` (chat), `/v1/add_question/` (ajout Q&A)

### Frontend (Next.js)
- Interface conversationnelle moderne
- Composants React rÃ©utilisables (Chat, SearchCard, etc.)
- Gestion d'Ã©tat et hooks personnalisÃ©s
- Design responsive avec Tailwind CSS

### Base de donnÃ©es vectorielle
- **ChromaDB** : stockage des embeddings pour la recherche sÃ©mantique
- **Sentence Transformers** : modÃ¨le multilingue pour les embeddings franÃ§ais

## ğŸ› ï¸ Stack technique

### Backend
- **FastAPI** : framework web moderne et performant
- **LangChain** : orchestration des modÃ¨les LLM et RAG
- **ChromaDB** : base de donnÃ©es vectorielle
- **Ollama** : dÃ©ploiement local de Llama3
- **HuggingFace Transformers** : embeddings multilingues (`paraphrase-multilingual-MiniLM-L12-v2`)
- **Python 3.10+**

### Frontend
- **Next.js 16** : framework React avec SSR
- **React 19** : bibliothÃ¨que UI
- **TypeScript** : typage statique
- **Tailwind CSS 4** : framework CSS utilitaire
- **Radix UI** : composants accessibles
- **Framer Motion** : animations

## ğŸ“ Structure du projet

```
LLM-GenAI_gr24/
â”œâ”€â”€ source/
â”‚   â”œâ”€â”€ backend/                 # API FastAPI
â”‚   â”‚   â”œâ”€â”€ api/                 # Routes et endpoints
â”‚   â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚   â”‚       â””â”€â”€ endpoints/   # ask.py, add_question.py
â”‚   â”‚   â”œâ”€â”€ schemas/             # ModÃ¨les Pydantic
â”‚   â”‚   â”œâ”€â”€ tools/               # RAG system, Ollama chat, document loader
â”‚   â”‚   â”œâ”€â”€ main.py              # Point d'entrÃ©e de l'application
â”‚   â”‚   â””â”€â”€ requirements.txt     # DÃ©pendances Python
â”‚   â”‚
â”‚   â”œâ”€â”€ frontend/                # Interface utilisateur
â”‚   â”‚   â””â”€â”€ help-center/         # Application Next.js
â”‚   â”‚       â”œâ”€â”€ app/             # Pages et layouts (App Router)
â”‚   â”‚       â”œâ”€â”€ components/      # Composants React
â”‚   â”‚       â”œâ”€â”€ hooks/           # Hooks personnalisÃ©s
â”‚   â”‚       â”œâ”€â”€ lib/             # Utilitaires
â”‚   â”‚       â””â”€â”€ types/           # Types TypeScript
â”‚   â”‚
â”‚   â””â”€â”€ database/
â”‚       â”œâ”€â”€ prod/                # Base ChromaDB de production
â”‚       â””â”€â”€ samples/             # DonnÃ©es d'exemple (JSON)
â”‚
â””â”€â”€ README.md                    # Ce fichier
```

## âš™ï¸ PrÃ©requis

Avant de commencer, assurez-vous d'avoir :

- **Python 3.12** installÃ©
- **Node.js 20+** et **npm**
- **Ollama** installÃ© ([https://ollama.ai](https://ollama.ai))
- **Git** pour cloner le repository
- Au moins **8 GB de RAM** (pour Llama3)

## ğŸš€ Installation et lancement

### 1. Cloner le projet

```bash
git clone https://github.com/GuillaumeRedon/LLM-GenAI_gr24.git
cd LLM-GenAI_gr24
```

### 2. Configuration Ollama

```bash
# DÃ©marrer le serveur Ollama (Terminal 1)
ollama serve

# TÃ©lÃ©charger le modÃ¨le Llama3 (Terminal 2)
ollama pull llama3
```

### 3. Backend - Installation et dÃ©marrage

```bash
cd source/backend

# CrÃ©er un environnement virtuel (recommandÃ©)
python3.12 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt

# Lancer le serveur
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

âœ… **Backend disponible** : [http://localhost:8000](http://localhost:8000)  
ğŸ“š **Documentation Swagger** : [http://localhost:8000/docs](http://localhost:8000/docs)

### 4. Frontend - Installation et dÃ©marrage

```bash
cd source/frontend/help-center

# Installer les dÃ©pendances
npm install

# Lancer l'application
npm run dev
```

âœ… **Frontend disponible** : [http://localhost:3000](http://localhost:3000)

## ğŸ” Variables d'environnement

### Backend (.env dans source/backend/)

```env
# Optionnel - Configuration ChromaDB ou autres services
DATABASE_PATH=../database/prod
```

### Frontend (.env.local dans source/frontend/help-center/)

```env
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## ğŸ“¦ Scripts principaux

### Backend

```bash
# DÃ©veloppement avec rechargement automatique
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Production
uvicorn main:app --host 0.0.0.0 --port 8000
```

### Frontend

```bash
npm run dev      # Mode dÃ©veloppement (port 3000)
npm run build    # Build de production
npm start        # Serveur de production
npm run lint     # VÃ©rification du code
```

## ğŸ§ª Utilisation

### Poser une question au chatbot

**Endpoint** : `POST /v1/ask/`

```json
{
  "messages": [
    { "role": "user", "content": "Quels sont les programmes de l'ESILV ?" }
  ]
}
```

### Ajouter une nouvelle Q&A

**Endpoint** : `POST /v1/add_question/`

```json
{
  "titre": "Admission ESILV",
  "contenu": "Les admissions se font via Parcoursup...",
  "thematique": "Admissions",
  "ecoles": "ESILV",
  "utilisateurs": "Candidats",
  "langue": "fr"
}
```

## ğŸ“š Bonnes pratiques

### Code
- **Backend** : respecter les conventions PEP 8 pour Python
- **Frontend** : utiliser TypeScript pour le typage fort
- **Commits** : messages clairs et descriptifs (ex : `feat: add chat history`)

### Architecture
- SÃ©parer la logique mÃ©tier dans `tools/` (backend)
- CrÃ©er des composants rÃ©utilisables (frontend)
- Utiliser les hooks personnalisÃ©s pour la logique d'Ã©tat

### Performance
- Les embeddings sont gÃ©nÃ©rÃ©s au premier lancement (peut prendre quelques minutes)
- ChromaDB persiste automatiquement les donnÃ©es
- Utiliser `search_kwargs={"k": 6}` pour limiter le nombre de documents rÃ©cupÃ©rÃ©s

### SÃ©curitÃ©
- Valider toutes les entrÃ©es utilisateur avec Pydantic (backend)
- Configurer CORS correctement en production
- Ne jamais exposer les clÃ©s API dans le code source

## ğŸ”— Ressources utiles

- [Documentation FastAPI](https://fastapi.tiangolo.com/)
- [Documentation LangChain](https://python.langchain.com/)
- [Ollama Models](https://ollama.ai/library)
- [Next.js Documentation](https://nextjs.org/docs)
- [ChromaDB Documentation](https://docs.trychroma.com/)

## ğŸ“„ Licence

Ce projet est rÃ©alisÃ© dans le cadre d'un projet acadÃ©mique pour l'ESILV.
