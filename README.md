# ESILV Smart Assistant

> Intelligent conversational assistant for the ESILV engineering school using RAG (Retrieval-Augmented Generation) technology and LLM models.

## ğŸ“– Project Overview

**ESILV Smart Assistant** is an intelligent chatbot designed to answer questions from students, candidates, and visitors about ESILV school (programs, admissions, courses, student life, etc.). It is build to assist the HelpCenter, a website that stores frequently asked questions. When a topic cannot be found using the existing hard-matching system, the user can use the Smart Assistant to get the answer it seeks. 

The system combines:
- **RAG (Retrieval-Augmented Generation)**: for factual answers based on official documentation
- **Multi-agent architecture**: to handle complex queries and structured interactions
- **Modern interface**: intuitive web interface for optimal user experience

### Use Cases
- Answer questions about programs and admissions
- Provide information on courses and student life
- Collect visitor details for personalized follow-up
- Semantic search in ESILV documentation

## ğŸ—ï¸ Architecture

The project follows a modern **client-server** architecture with **multi-agent system**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚ HTTP    â”‚     Backend (Multi-Agent)    â”‚         â”‚    Ollama      â”‚
â”‚   (Next.js)     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   (FastAPI + LangGraph)      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  (Gemma2:2b)   â”‚
â”‚   Port 3000     â”‚         â”‚   Port 8000                  â”‚         â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚   ChromaDB     â”‚
                            â”‚ (Vector Store) â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Multi-Agent Workflow:
  Agent 1: Document Retriever â†’ Agent 2: Answer Generator â†’ Agent 3: Quality Validator
```

### Backend (FastAPI + LangChain + LangGraph)
- REST API for the chatbot
- **Multi-agent RAG system** with 3 specialized agents
- RAG with ChromaDB and HuggingFace embeddings
- Ollama (Gemma2:2b) integration for fast response generation
- Endpoints: `/v1/ask_agent/` (multi-agent), `/v1/add_question/` (add Q&A)

### Frontend (Next.js)
- Modern conversational interface
- Reusable React components (Chat, SearchCard, etc.)
- State management and custom hooks
- Responsive design with Tailwind CSS

### Vector Database
- **ChromaDB**: storage of embeddings for semantic search
- **Sentence Transformers**: multilingual model for French embeddings

## ğŸ› ï¸ Technical Stack

### Backend
- **FastAPI**: modern and performant web framework
- **LangChain**: orchestration of LLM and RAG models
- **LangGraph**: multi-agent workflow orchestration
- **ChromaDB**: vector database
- **Ollama**: local deployment of LLMs (Gemma2:2b for agents)
- **HuggingFace Transformers**: multilingual embeddings (`paraphrase-multilingual-MiniLM-L12-v2`)
- **Python 3.10+**

### Frontend
- **Next.js 16**: React framework with SSR
- **React 19**: UI library
- **TypeScript**: static typing
- **Tailwind CSS 4**: utility CSS framework
- **Radix UI**: accessible components
- **Framer Motion**: animations

## ğŸ“ Project Structure

```
LLM-GenAI_gr24/
â”œâ”€â”€ source/
â”‚   â”œâ”€â”€ backend/                 # FastAPI API
â”‚   â”‚   â”œâ”€â”€ agents/              # Multi-agent system (LangGraph)
â”‚   â”‚   â”‚   â”œâ”€â”€ state.py         # Agent state schema
â”‚   â”‚   â”‚   â”œâ”€â”€ nodes.py         # Agent node functions
â”‚   â”‚   â”‚   â”œâ”€â”€ graph.py         # Workflow orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ tools.py         # Agent tools (RAG wrapper)
â”‚   â”‚   â”‚   â””â”€â”€ README.md        # Agents Orchestration README
â”‚   â”‚   â”œâ”€â”€ api/                 # Routes and endpoints
â”‚   â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚   â”‚       â””â”€â”€ endpoints/   # ask.py, ask_agent.py, add_question.py
â”‚   â”‚   â”œâ”€â”€ schemas/             # Pydantic models
â”‚   â”‚   â”œâ”€â”€ tools/               # RAG system, Ollama chat, document loader
â”‚   â”‚   â”œâ”€â”€ main.py              # Application entry point
â”‚   â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â”‚   â””â”€â”€ README.md            # Backend README
â”‚   â”‚
â”‚   â”‚
â”‚   â”œâ”€â”€ frontend/                # User interface
â”‚   â”‚   â””â”€â”€ help-center/         # Next.js application
â”‚   â”‚       â”œâ”€â”€ app/             # Pages and layouts (App Router)
â”‚   â”‚       â”œâ”€â”€ components/      # React components
â”‚   â”‚       â”œâ”€â”€ hooks/           # Custom hooks
â”‚   â”‚       â”œâ”€â”€ lib/             # Utilities
â”‚   â”‚       â”œâ”€â”€ types/           # TypeScript types
â”‚   â”‚       â””â”€â”€ README.md        # Frontend README
â”‚   â”‚
â”‚   â””â”€â”€ database/
â”‚       â”œâ”€â”€ prod/                # Production ChromaDB database
â”‚       â””â”€â”€ samples/             # Sample data (JSON)
â”‚
â””â”€â”€ README.md                    # This file
```

## âš™ï¸ Prerequisites

Before starting, make sure you have:

- **Python 3.12** installed
- **Node.js 20+** and **npm**
- **Ollama** installed ([https://ollama.ai](https://ollama.ai))
- **Git** to clone the repository

## ğŸš€ Installation and Launch

### 1. Clone the Project

```bash
git clone https://github.com/GuillaumeRedon/LLM-GenAI_gr24.git
cd LLM-GenAI_gr24
```

### 2. Ollama Configuration

```bash
# Start the Ollama server (Terminal 1)
ollama serve

# Download the models (Terminal 2)
ollama pull gemma2:2b      # For multi-agent system (faster)
```

### 3. Backend - Installation and Startup

```bash
cd source/backend

# Create a virtual environment (recommended)
python3.12 -m venv .venv
source .venv/bin/activate  # Linux/Mac
# or
.venv\Scripts\activate.ps1     # Windows

# Install dependencies
pip install -r requirements.txt

# Start the server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

âœ… **Backend available**: [http://localhost:8000](http://localhost:8000)  
ğŸ“š **Swagger documentation**: [http://localhost:8000/docs](http://localhost:8000/docs)

### 4. Frontend - Installation and Startup

```bash
cd source/frontend/help-center

# Install dependencies
npm install

# Start the application
npm run dev
```

âœ… **Frontend available**: [http://localhost:3000](http://localhost:3000)

## ğŸ” Environment Variables

### Backend (.env in source/backend/)

```env
# Optional - ChromaDB configuration or other services
DATABASE_PATH=../database/prod
```

### Frontend (.env.local in source/frontend/help-center/)

```env
NEXT_PUBLIC_API_URL=http://localhost:8000
```

## ğŸ“¦ Main Scripts

### Backend

```bash
# Development with automatic reload
uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Production
uvicorn main:app --host 0.0.0.0 --port 8000
```

### Frontend

```bash
npm run dev      # Development mode (port 3000)
npm run build    # Production build
npm start        # Production server
npm run lint     # Code verification
```

## ğŸ§ª Usage

### Ask a Question to the Chatbot

**Multi-Agent Endpoint**: `POST /v1/ask_agent/`

```json
{
  "messages": [
    { "role": "user", "content": "What are the ESILV programs?" }
  ]
}
```

### Add a New Q&A

**Endpoint**: `POST /v1/add_question/`

```json
{
  "titre": "ESILV Admission",
  "contenu": "Admissions are done through Parcoursup...",
  "thematique": "Admissions",
  "ecoles": "ESILV",
  "utilisateurs": "Candidats",
  "langue": "fr"
}
```

## ğŸ“š Best Practices

### Code
- **Backend**: follow PEP 8 conventions for Python
- **Frontend**: use TypeScript for strong typing
- **Commits**: clear and descriptive messages (e.g., `feat: add chat history`)

### Architecture
- Separate business logic in `tools/` (backend)
- Create reusable components (frontend)
- Use custom hooks for state logic

### Performance
- Embeddings are generated on first launch (may take a few minutes)
- ChromaDB automatically persists data
- Use `search_kwargs={"k": 6}` to limit the number of retrieved documents

### Security
- Validate all user inputs with Pydantic (backend)
- Configure CORS correctly in production
- Never expose API keys in source code

## ğŸ”— Useful Resources

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [LangChain Documentation](https://python.langchain.com/)
- [Ollama Models](https://ollama.ai/library)
- [Next.js Documentation](https://nextjs.org/docs)
- [ChromaDB Documentation](https://docs.trychroma.com/)

## ğŸ“„ License

This project is carried out as part of an academic project for ESILV.